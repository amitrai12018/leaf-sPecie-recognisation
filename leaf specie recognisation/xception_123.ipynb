{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt                 \nimport matplotlib.image as mpimg\ntraining_data_dir= '/kaggle/input/leaf-classification/dataset/train'     #importing training data\nvalidation_data_dir='/kaggle/input/leaf-classification/dataset/test'     #importing test data \nIMAGE_SIZE = 224                                                      \nIMAGE_WIDTH, IMAGE_HEIGHT = IMAGE_SIZE, IMAGE_SIZE                       # Size of image = 224*224*3\nEPOCHS = 25                                                              # Number of epoches \nBATCH_SIZE = 64                                                          # Size of batch \nTEST_SIZE = 30                                            \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_shape = (IMAGE_WIDTH, IMAGE_HEIGHT, 3)   # Size of Image = [224,224,3]\nimport tensorflow as tf                        # Importing tensorflow\nimport tensorflow.keras                        # Importing Keras from tensorflow\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator        #importing Image-data-generator class from kreas that is used for augmentation of image\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, SeparableConv2D, UpSampling2D # importing attributes that will be used for making layers \nfrom tensorflow.keras.models import Model\n                                                                                                                             \nfrom tensorflow.keras.layers import  GlobalAveragePooling2D , Input ,  BatchNormalization   #import attributes that will be used for making layers  \n\n\n\ntraining_data_generator = ImageDataGenerator(\n    rescale=1./255,\n    horizontal_flip=True,\n    vertical_flip=True,\n    rotation_range=60 ,\n    brightness_range=[0.5 , 1.0]\n    \n    )                                                 #training data image augmentation \nvalidation_data_generator = ImageDataGenerator(rescale=1./255,\n         horizontal_flip=True,\n    vertical_flip=True,\n    rotation_range=60,\n    brightness_range=[0.5 , 1.0])                    #validation data augmentation \ntraining_generator = training_data_generator.flow_from_directory(\n    training_data_dir,\n    target_size=(IMAGE_WIDTH, IMAGE_HEIGHT),\n    batch_size=BATCH_SIZE,\n    shuffle = True,\n    class_mode=\"categorical\")                      #generating tarining data\n\nvalidation_generator = validation_data_generator.flow_from_directory(\n    validation_data_dir,\n    target_size=(IMAGE_WIDTH, IMAGE_HEIGHT),\n    batch_size=BATCH_SIZE,\n    shuffle = True,\n    class_mode=\"categorical\")                   #generating validation data \n ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# In Xception model ,The data first goes through the entry flow, then through the middle flow , and finally through the exit flow ,so here is the entery flow.\ndef entry_flow(inputs) :                   # X\n\n    x = Conv2D(32,(3,3), strides = 2, padding='valid')(inputs)       # 2D convlational layer with size (32,3*3) , strides =2*2\n    x = BatchNormalization()(x)                                     # Applying batch norm on (X) to imporve network training \n    x = Activation('relu')(x)                                       # relu Activation on batch-normalised layer \n\n\n    x = Conv2D(64,(3,3),padding='same')(x)                          #2D convulational layer with size (32, 3*3) , strides = 1*1\n    x = BatchNormalization()(x)                                      # Applying batch norm on (X) to imporve network training    \n    x = Activation('relu')(x)                                        # relu Activation on batch-normalsied layer \n    x=Dropout(0.2)(x)                                                #\n    previous_block_activation = x                                    #saving activation of this layer to a variable known as privious_block_activation \n\n    for size in [128, 256, 728] :                                    \n\n        x = Activation('relu')(x)                                     # relu Activation\n        x = SeparableConv2D(size, 3, padding='same')(x)               # Separable Convolution 2D layer of Size=size\n        x = BatchNormalization()(x)                                    # Applying batch norm on (X) to imporve network training \n\n        x = Activation('relu')(x)                                    # relu Activation on x\n        x = SeparableConv2D(size, 3, padding='same')(x)              # Separable Convolution 2D layer of Size=size\n        x = BatchNormalization()(x)                                  # Applying batch norm on (x) to imporve network training \n\n        x = MaxPooling2D(3, strides=2, padding='same')(x)           # applying maxpooling to x with size 3*3\n        x=Dropout(0.2)(x)                                           # dropout on x with value 0.2\n        residual = Conv2D(size, 1, strides=2, padding='same')(previous_block_activation)        # forming a convulational layer on previous activation block and storing in residual \n\n        x = tensorflow.keras.layers.Add()([x, residual])           # combining x and residual \n        previous_block_activation = x                           \n\n    return x\n# next is the middle layer of the xception model \ndef middle_flow(x, num_blocks=8) : # x is the input taht came from output of the entry layer , num_block=8 represents that in  the  middle_flow the training is done 8 times  \n                              \n    previous_block_activation = x\n    ##teh process of depthwise convulation is repeated 8 times as it was done for entry_flow function .\n    for _ in range(num_blocks) :\n\n        x = Activation('relu')(x)                                     \n        x = SeparableConv2D(728, (3,3), padding='same')(x)         \n        x = BatchNormalization()(x)\n\n        x = Activation('relu')(x)\n        x = SeparableConv2D(728,( 3,3), padding='same')(x)\n        x = BatchNormalization()(x)\n       \n        x = Activation('relu')(x)\n        x = SeparableConv2D(728, (3,3), padding='same')(x)\n        x = BatchNormalization()(x)\n        x=Dropout(0.2)(x)\n        x = tensorflow.keras.layers.Add()([x, previous_block_activation])\n        previous_block_activation = x\n\n    return x\n\n# after the middle_flow comes the exit_flow\n# in the exit folw the depthwise convulation is applied as it was applied in entry_flow and middle_flow\n\ndef exit_flow(x) :\n   \n    previous_block_activation = x\n\n    x = Activation('relu')(x)\n    x = SeparableConv2D(728,( 3,3), padding='same')(x)\n    x = BatchNormalization()(x)\n    \n    x = Activation('relu')(x)\n    x = SeparableConv2D(1024, (3,3), padding='same')(x) \n    x = BatchNormalization()(x)\n\n    x = MaxPooling2D(3, strides=2, padding='same')(x)\n    x=Dropout(0.2)(x)\n    residual = Conv2D(1024, (1,1), strides=2, padding='same')(previous_block_activation)\n    x = tensorflow.keras.layers.Add()([x, residual])\n\n    x = Activation('relu')(x)\n    x = SeparableConv2D(728, (3,3), padding='same')(x)\n    x = BatchNormalization()(x)\n\n    x = Activation('relu')(x)\n    x = SeparableConv2D(1024,(3,3), padding='same')(x)\n    x = BatchNormalization()(x)\n    x=Dropout(0.2)(x)\n    x = GlobalAveragePooling2D()(x)         # here avergae pooling is done instead of max pooiling as it retains more results than avergae pooling \n    \n    x = Dense(185, activation='softmax')(x)    # finally the output is being computed by softmax funtion\n\n    return x\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inputs = Input(shape=(224, 224, 3))   \noutputs = exit_flow(middle_flow(entry_flow(inputs)))  # calling output function \nxception = Model(inputs, outputs)             # creating an modle named xception out of input and output from output from the exit_flow\n#model=xception.summary()\nfrom tensorflow.keras.callbacks import EarlyStopping    # importing earlystopping from kears.callbacks \n#es=tensorflow.keras.callbacks.EarlyStopping(monitor='val_loss',patience=5,verbose=1)\nxception.compile(optimizer = tensorflow.keras.optimizers.Adam(lr = 0.001), loss='categorical_crossentropy', metrics=['accuracy'])  # compiling the model using adam optimiser setting \n                                                                                                                                   # learning rate =0.01 , and setting loss as categorical crossentropy as more than 2 classes are being used to train \n                                                                                                                                   #setting metrices to accuracy to monitor acuracy \n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history=xception.fit_generator(\n    training_generator,\n    steps_per_epoch=len(training_generator.filenames) // BATCH_SIZE,\n    epochs=15,\n    validation_data=validation_generator,\n    validation_steps=len(validation_generator.filenames) // BATCH_SIZE)\n\n### training the model on training data for 15 epoches  with optimiser as Adam with learning rate =0.01\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nxception.compile(optimizer = tensorflow.keras.optimizers.Adam(lr = 0.001),\n              loss='categorical_crossentropy', metrics=['accuracy',])\nhistory=xception.fit_generator(\n    training_generator,\n    steps_per_epoch=len(training_generator.filenames) // BATCH_SIZE,\n    epochs=15,\n    validation_data=validation_generator,\n    validation_steps=len(validation_generator.filenames) // BATCH_SIZE\n           )     \n### training the model on training data for 15 epoches  with optimiser as Adam with learning rate =0.001\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint     # importing ModleCheckpoint from keras.callbacks\ncheckpointer = ModelCheckpoint(filepath='model.h5',monitor = 'val_loss', verbose=1, save_best_only=True) #assigning a checkpointer to save weights to model.h5 file and mointor validation loss \ncallbacks = [ checkpointer]                                                                              # save_best_only=True means save weights only if the validation loss improved in that epoch\n\nxception.compile(optimizer = tensorflow.keras.optimizers.Adam(lr = 0.0001),\n              loss='categorical_crossentropy', metrics=['accuracy',])   #  compiling the model with adam optimiser with learning rate =0.0001 . \nhistory=xception.fit_generator(\n    training_generator,\n    steps_per_epoch=len(training_generator.filenames) // BATCH_SIZE,\n    epochs=5,\n    validation_data=validation_generator,\n    validation_steps=len(validation_generator.filenames) // BATCH_SIZE,\n   callbacks = [ checkpointer]        )\n# training the model with training data and validating using validation data and also applying a checkpointer .","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}